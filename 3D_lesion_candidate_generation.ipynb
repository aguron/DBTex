{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlrd\n",
    "!pip install --upgrade pandas\n",
    "!pip install openpyxl\n",
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "import glob\n",
    "import torchvision.ops as ops\n",
    "import torch\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '' # <specified location of SPIE data and metadata>\n",
    "train_labels = pd.read_csv(os.path.join(location,'BCS-DBT labels-train.csv'))\n",
    "train_boxes = pd.read_csv(os.path.join(location,'BCS-DBT boxes-train.csv'))\n",
    "train_paths = pd.read_csv(os.path.join(location,'BCS-DBT file-paths-train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a bounding box prediction for a single slice in a DBT volume\n",
    "# output by the Faster R-CNN detector\n",
    "#\n",
    "# {'boxes': array([[ 626.5633, 1347.9958,  729.663 , 1417.5177]], dtype=float32), 'labels': array([1]), 'scores': array([0.08185726], dtype=float32)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------\n",
    "# Functions\n",
    "# ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sls_to_vol(sls,\n",
    "               continuity=0.03,\n",
    "               score_threshold=0.25,\n",
    "               depth_threshold=0.02,\n",
    "               intersection_thresholds=[0,1],\n",
    "               intersection_mode='IoSIB',\n",
    "               box_scores_function=np.mean,\n",
    "               top_n_scores=1,\n",
    "               weighted_boxes_fusion=False):\n",
    "    '''\n",
    "    continuity: fraction of slices without boxes to be tolerated as gaps\n",
    "    \n",
    "    assumes:\n",
    "        that all the slices in sls are ordered\n",
    "    handles:\n",
    "        situation where slice groups overlap later\n",
    "    '''\n",
    "    continuity = int(np.ceil(continuity * len(sls)))\n",
    "    \n",
    "    if depth_threshold < 1:\n",
    "        depth_threshold = int(np.ceil(depth_threshold * len(sls)))\n",
    "    \n",
    "    slice_groups = {}\n",
    "    boxes3D = {}\n",
    "    if weighted_boxes_fusion:\n",
    "        scores = {}\n",
    "    box2D_scores = {}\n",
    "    for i in range(len(sls)):\n",
    "        sl_boxes = sls[i]['boxes']\n",
    "        sl_scores = sls[i]['scores']\n",
    "\n",
    "        if len(sl_scores) == 0:\n",
    "            sl_scores = np.array([])\n",
    "        elif type(sl_scores[0]) == np.ndarray:\n",
    "            sl_scores = [box_scores_function(_) for _ in sl_scores]\n",
    "\n",
    "        # non-maximum suppression (NMS)\n",
    "        if intersection_thresholds[1] < 1:\n",
    "            idx = ops.nms(torch.from_numpy(sl_boxes),\n",
    "                          torch.from_numpy(sl_scores),\n",
    "                          iou_threshold=intersection_thresholds[1])\n",
    "            sl_boxes = sl_boxes[idx.numpy()]\n",
    "            sl_scores = sl_scores[idx.numpy()]\n",
    "\n",
    "        for bi in range(len(sl_boxes)):\n",
    "            appended = False\n",
    "            if len(slice_groups) > 0:\n",
    "                for j in slice_groups:\n",
    "                    if appended:\n",
    "                        break\n",
    "                    if intersection2d(sl_boxes[bi][[0,2]],\n",
    "                                      boxes3D[j]['x'],\n",
    "                                      sl_boxes[bi][[1,3]],\n",
    "                                      boxes3D[j]['y'],\n",
    "                                      b_intersection_thr=intersection_thresholds[0],\n",
    "                                      intersection_mode=intersection_mode) and \\\n",
    "                        (i - continuity) <= max(slice_groups[j]) and \\\n",
    "                        sl_scores[bi] > score_threshold:\n",
    "                        \n",
    "                        if weighted_boxes_fusion:\n",
    "                            boxes3D[j]['x'][0] = (scores[j]*boxes3D[j]['x'][0] +\n",
    "                                                  sl_scores[bi]*sl_boxes[bi][0])/ \\\n",
    "                                                 (scores[j] + sl_scores[bi])\n",
    "                            boxes3D[j]['x'][1] = (scores[j]*boxes3D[j]['x'][1] +\n",
    "                                                  sl_scores[bi]*sl_boxes[bi][2])/ \\\n",
    "                                                 (scores[j] + sl_scores[bi])\n",
    "                            boxes3D[j]['y'][0] = (scores[j]*boxes3D[j]['y'][0] +\n",
    "                                                  sl_scores[bi]*sl_boxes[bi][1])/ \\\n",
    "                                                 (scores[j] + sl_scores[bi])\n",
    "                            boxes3D[j]['y'][1] = (scores[j]*boxes3D[j]['y'][1] +\n",
    "                                                  sl_scores[bi]*sl_boxes[bi][3])/ \\\n",
    "                                                 (scores[j] + sl_scores[bi])\n",
    "                            scores[j] += sl_scores[bi]\n",
    "                        else:\n",
    "                            if sl_boxes[bi][0] < boxes3D[j]['x'][0]:\n",
    "                                boxes3D[j]['x'][0] = sl_boxes[bi][0]\n",
    "                            if sl_boxes[bi][2] > boxes3D[j]['x'][1]:\n",
    "                                boxes3D[j]['x'][1] = sl_boxes[bi][2]\n",
    "                            if sl_boxes[bi][1] < boxes3D[j]['y'][0]:\n",
    "                                boxes3D[j]['y'][0] = sl_boxes[bi][1]\n",
    "                            if sl_boxes[bi][3] > boxes3D[j]['y'][1]:\n",
    "                                boxes3D[j]['y'][1] = sl_boxes[bi][3]\n",
    "\n",
    "                        slice_groups[j].append(i)\n",
    "\n",
    "                        boxes3D[j]['z'][0] = min(slice_groups[j])\n",
    "                        boxes3D[j]['z'][1] = max(slice_groups[j])\n",
    "\n",
    "                        box2D_scores[j].append(sl_scores[bi])\n",
    "                        \n",
    "                        appended = True\n",
    "                        break\n",
    "            if not appended and sl_scores[bi] > score_threshold:\n",
    "                if weighted_boxes_fusion:\n",
    "                    scores[len(slice_groups)] = sl_scores[bi]\n",
    "                boxes3D[len(slice_groups)] = {}\n",
    "                boxes3D[len(slice_groups)]['x'] = list(sl_boxes[bi][[0,2]])\n",
    "                boxes3D[len(slice_groups)]['y'] = list(sl_boxes[bi][[1,3]])\n",
    "                boxes3D[len(slice_groups)]['z'] = [i, i]\n",
    "                box2D_scores[len(slice_groups)] = [sl_scores[bi]]\n",
    "                slice_groups[len(slice_groups)] = [i]\n",
    "\n",
    "    slice_groups_temp = {}\n",
    "    boxes3D_temp = {}\n",
    "    if weighted_boxes_fusion:\n",
    "        scores_temp = {}\n",
    "    box2D_scores_temp = {}\n",
    "    while True:\n",
    "        for i in range(len(boxes3D)):\n",
    "            appended = False\n",
    "            if len(slice_groups_temp) > 0:\n",
    "                for j in range(len(boxes3D_temp)):\n",
    "                    if intersection2d(boxes3D[i]['x'],\n",
    "                                      boxes3D[j]['x'],\n",
    "                                      boxes3D[i]['y'],\n",
    "                                      boxes3D[j]['y'],\n",
    "                                      b_intersection_thr=intersection_thresholds[0],\n",
    "                                      intersection_mode=intersection_mode) and \\\n",
    "                      (boxes3D[i]['z'][1] > boxes3D[j]['z'][0] and \\\n",
    "                       boxes3D[j]['z'][1] > boxes3D[i]['z'][0] or \\\n",
    "                       abs(min(boxes3D[i]['z']) - max(boxes3D[j]['z'])) < continuity or \\\n",
    "                       abs(min(boxes3D[j]['z']) - max(boxes3D[i]['z'])) < continuity):\n",
    "\n",
    "                        if weighted_boxes_fusion:\n",
    "                            for coord in 'xyz':\n",
    "                                for boundary in range(2):\n",
    "                                    boxes3D_temp[j][coord][boundary] =\\\n",
    "                                        (scores_temp[j]*boxes3D_temp[j][coord][boundary] +\n",
    "                                         scores[i]*boxes3D[i][coord][boundary])/ \\\n",
    "                                        (scores_temp[j] + scores[i])\n",
    "                                scores_temp[j] += scores[i]\n",
    "                        else:\n",
    "                            for coord in 'xyz':\n",
    "                                if boxes3D[i][coord][0] < boxes3D_temp[j][coord][0]:\n",
    "                                    boxes3D_temp[j][coord][0] = boxes3D[i][coord][0]\n",
    "                                if boxes3D[i][coord][1] > boxes3D_temp[j][coord][1]:\n",
    "                                    boxes3D_temp[j][coord][1] = boxes3D[i][coord][1]\n",
    "\n",
    "                        slice_groups_temp[j] =\\\n",
    "                            slice_groups_temp[j] + slice_groups[i]\n",
    "\n",
    "                        box2D_scores_temp[j] =\\\n",
    "                            box2D_scores_temp[j] + box2D_scores[i]\n",
    "\n",
    "                        appended = True\n",
    "                        break\n",
    "            if not appended:\n",
    "                slice_groups_temp[len(box2D_scores_temp)] = slice_groups[i]\n",
    "                boxes3D_temp[len(box2D_scores_temp)] = boxes3D[i]\n",
    "                if weighted_boxes_fusion:\n",
    "                    scores_temp[len(box2D_scores_temp)] = scores[i]\n",
    "                box2D_scores_temp[len(box2D_scores_temp)] = box2D_scores[i]\n",
    "\n",
    "        if boxes3D == boxes3D_temp:\n",
    "            break                \n",
    "                \n",
    "    slice_groups = {}\n",
    "    boxes3D = {}\n",
    "    scores = {}\n",
    "    box2D_scores = {}\n",
    "    for i in range(len(boxes3D_temp)):\n",
    "        depth = int(np.diff(boxes3D_temp[i]['z'])) + 1\n",
    "        if depth <= depth_threshold:\n",
    "            continue\n",
    "        slice_groups[len(scores)] = slice_groups_temp[i]\n",
    "        boxes3D[len(scores)] = boxes3D_temp[i]\n",
    "        box2D_scores[len(scores)] = box2D_scores_temp[i]\n",
    "        scores[len(scores)] = np.mean(sorted(box2D_scores[len(scores)])[-top_n_scores:])\n",
    "\n",
    "    return slice_groups, boxes3D, scores, box2D_scores\n",
    "\n",
    "\n",
    "def intersection2d(b1_x,b2_x,b1_y,b2_y,b_intersection_thr=0,intersection_mode='IoSIB'):\n",
    "    i_x = (b1_x[1] - b2_x[0], b2_x[1] - b1_x[0])\n",
    "    i_y = (b1_y[1] - b2_y[0], b2_y[1] - b1_y[0])\n",
    "    \n",
    "    \n",
    "    if intersection_mode == 'IoU':\n",
    "        intersection_ind = min(i_x) > 0 and min(i_y) > 0 and \\\n",
    "                           np.prod((min(i_x),min(i_y))) \\\n",
    "                           / (np.prod((np.diff(b1_x),np.diff(b1_y))) + \\\n",
    "                              np.prod((np.diff(b2_x),np.diff(b2_y))) - \\\n",
    "                              np.prod((min(i_x),min(i_y)))) \\\n",
    "                           > b_intersection_thr\n",
    "    elif intersection_mode == 'IoSIB':\n",
    "        intersection_ind = min(i_x) > 0 and min(i_y) > 0 and \\\n",
    "                           np.prod((min(i_x),min(i_y))) / \\\n",
    "                           min(np.prod((np.diff(b1_x),np.diff(b1_y))),\n",
    "                               np.prod((np.diff(b2_x),np.diff(b2_y)))) \\\n",
    "                           > b_intersection_thr    \n",
    "    return intersection_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Candidate Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tps(df_pred: pd.DataFrame,\n",
    "             df_true: pd.DataFrame,\n",
    "             num_slices_info: dict\n",
    "            ) -> pd.DataFrame:\n",
    "\n",
    "    df_pred = df_pred.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "    df_true = df_true.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "    \n",
    "    df_pred['TP'] = 0\n",
    "    df_pred['GTID'] = -1\n",
    "    \n",
    "    # find true positive predictions and assign detected ground truth box ID\n",
    "    for pred in df_pred.itertuples():\n",
    "        if pred.Index not in df_true.index:\n",
    "            continue\n",
    "        df_true_temp = df_true.loc[[pred.Index]]\n",
    "  \n",
    "        tps = [\n",
    "            tp\n",
    "            for tp in df_true_temp.itertuples()\n",
    "            if is_tp(pred, tp,\n",
    "                     slice_offset=\\\n",
    "                         num_slices_info[pred.PatientID][pred.Index[0]][pred.Index[1]] / 4)\n",
    "        ]\n",
    "\n",
    "        if len(tps) > 1:\n",
    "            # find the nearest GT box\n",
    "            tp_distances = [distance(pred, tp) for tp in tps]\n",
    "            tps = [tps[np.argmin(tp_distances)]]\n",
    "\n",
    "        if len(tps) > 0:\n",
    "            df_pred.loc[df_pred[\"index\"] == pred.index, ('TP', 'GTID')] = (1, tps[0].index)\n",
    "    \n",
    "    return df_pred\n",
    "\n",
    "def evaluate(df_labels: pd.DataFrame,\n",
    "             df_pred: pd.DataFrame,\n",
    "             df_true: pd.DataFrame,\n",
    "             num_slices_info: dict,\n",
    "             fps_per_vol: tuple = (1.0, 2.0, 3.0, 4.0,)\n",
    "            ) -> dict:\n",
    "    \n",
    "    df_labels = df_labels.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "    df_pred = df_pred.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "    df_true = df_true.reset_index().set_index([\"StudyUID\", \"View\"]).sort_index()\n",
    "    \n",
    "    df_pred['TP'] = 0\n",
    "    df_pred['GTID'] = -1\n",
    "\n",
    "    thresholds = [df_pred['Score'].max() + 1.0]\n",
    "    \n",
    "    # find true positive predictions and assign detected ground truth box ID\n",
    "    for pred in df_pred.itertuples():\n",
    "        if pred.Index not in df_true.index:\n",
    "            continue\n",
    "        df_true_temp = df_true.loc[[pred.Index]]\n",
    "  \n",
    "        tps = [\n",
    "            tp\n",
    "            for tp in df_true_temp.itertuples()\n",
    "            if is_tp(pred, tp,\n",
    "                     slice_offset=\\\n",
    "                         num_slices_info[pred.PatientID][pred.Index[0]][pred.Index[1]] / 4)\n",
    "        ]\n",
    "\n",
    "        if len(tps) > 1:\n",
    "            # find the nearest GT box\n",
    "            tp_distances = [distance(pred, tp) for tp in tps]\n",
    "            tps = [tps[np.argmin(tp_distances)]]\n",
    "\n",
    "        if len(tps) > 0:\n",
    "            df_pred.loc[df_pred[\"index\"] == pred.index, ('TP', 'GTID')] = (1, tps[0].index)\n",
    "            thresholds.append(pred.Score)\n",
    "\n",
    "    thresholds.append(df_pred['Score'].min() - 1.0)\n",
    "\n",
    "    # compute sensitivity at specified FPs/volume on all cases\n",
    "    tpr_all = froc(df_pred=df_pred,\n",
    "                   thresholds=thresholds,\n",
    "                   n_volumes=len(df_labels),\n",
    "                   n_boxes=len(df_true),\n",
    "                   evaluation_fps=fps_per_vol\n",
    "                  )\n",
    "\n",
    "    # compute sensitivity at specified FPs/volume on positive cases\n",
    "    df_pred = df_pred[df_pred.index.isin(df_true.index)]\n",
    "    df_labels = df_labels[df_labels.index.isin(df_true.index)]\n",
    "    tpr_positive = froc(df_pred=df_pred,\n",
    "                        thresholds=thresholds,\n",
    "                        n_volumes=len(df_labels),\n",
    "                        n_boxes=len(df_true),\n",
    "                        evaluation_fps=fps_per_vol\n",
    "                       )\n",
    "    \n",
    "    return tpr_positive, tpr_all\n",
    "\n",
    "\n",
    "def froc(df_pred: pd.DataFrame,\n",
    "         thresholds: list,\n",
    "         n_volumes: int,\n",
    "         n_boxes: int,\n",
    "         evaluation_fps: tuple\n",
    "        ) -> list:\n",
    "    tpr = []\n",
    "    fps = []\n",
    "    for th in sorted(thresholds, reverse=True):\n",
    "        df_th = df_pred.loc[df_pred[\"Score\"] >= th]\n",
    "        df_th_unique_tp = df_th.reset_index().drop_duplicates(\n",
    "            subset=[\"StudyUID\", \"View\", \"TP\", \"GTID\"]\n",
    "        )\n",
    "        n_tps_th = float(sum(df_th_unique_tp[\"TP\"]))\n",
    "        tpr_th = n_tps_th / n_boxes\n",
    "        n_fps_th = float(len(df_th[df_th[\"TP\"] == 0]))\n",
    "        fps_th = n_fps_th / n_volumes\n",
    "        tpr.append(tpr_th)\n",
    "        fps.append(fps_th)\n",
    "        if fps_th > max(evaluation_fps):\n",
    "            break\n",
    "    return [np.interp(x, fps, tpr) for x in evaluation_fps]\n",
    "\n",
    "\n",
    "def distance(pred, true):\n",
    "    pred_y = pred.Y + pred.Height / 2\n",
    "    pred_x = pred.X + pred.Width / 2\n",
    "    pred_z = pred.Z + pred.Depth / 2\n",
    "    true_y = true.Y + true.Height / 2\n",
    "    true_x = true.X + true.Width / 2\n",
    "    true_z = true.Slice\n",
    "    return np.linalg.norm((pred_x - true_x, pred_y - true_y, pred_z - true_z))\n",
    "\n",
    "def is_tp(pred, true, slice_offset, min_dist=100):\n",
    "    pred_x = pred.X + pred.Width / 2\n",
    "    pred_y = pred.Y + pred.Height / 2\n",
    "    pred_z = pred.Z + pred.Depth / 2\n",
    "    \n",
    "    true_x = true.X + true.Width / 2\n",
    "    true_y = true.Y + true.Height / 2\n",
    "    true_z = true.Slice\n",
    "    \n",
    "    # 2D distance between true and predicted center points\n",
    "    dist = np.linalg.norm((pred_x - true_x, pred_y - true_y))\n",
    "\n",
    "    # compute radius based on true box size\n",
    "    dist_threshold = np.sqrt(true.Width ** 2 + true.Height ** 2) / 2.0\n",
    "    dist_threshold = max(dist_threshold, min_dist)\n",
    "    slice_diff = np.abs(pred_z - true_z)\n",
    "    \n",
    "    # TP if predicted center within radius and slice within slice offset\n",
    "    return dist <= dist_threshold and slice_diff <= slice_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Candidate Generation Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_dbtex(df_pred: pd.DataFrame, num_slices_info: dict) -> pd.DataFrame:\n",
    "    df_pred = df_pred.reset_index().set_index([\"StudyUID\", \"View\"])\n",
    "    indices = np.unique(df_pred.index, return_index=True)[1]\n",
    "    indices = [df_pred.index[_] for _ in sorted(indices)]\n",
    "    df_pred = df_pred.sort_index()\n",
    "    df_pred_new = pd.DataFrame(columns=['PatientID','StudyUID','View',\n",
    "                                        'X','Width','Y','Height','Z','Depth',\n",
    "                                        'Score',\n",
    "                                        'index'])\n",
    "    for index in indices:\n",
    "        df_temp = pd.DataFrame(columns=['PatientID','StudyUID','View',\n",
    "                                        'X','Width','Y','Height','Z','Depth',\n",
    "                                        'Score',\n",
    "                                        'index'])\n",
    "        for pred in df_pred.loc[index].sort_values(['Score']).itertuples():\n",
    "            added = False\n",
    "            if len(df_temp) != 0:\n",
    "                for temp in df_temp.itertuples():\n",
    "                    if is_match(temp, pred,\n",
    "                                num_slices_info[temp.PatientID][temp.StudyUID][temp.View] / 4):\n",
    "                        df_temp.loc[temp.Index,'PatientID'] = pred.PatientID\n",
    "                        df_temp.loc[temp.Index,'StudyUID'] = pred.Index[0]\n",
    "                        df_temp.loc[temp.Index,'View'] = pred.Index[1]\n",
    "                        df_temp.loc[temp.Index,'X'] = pred.X\n",
    "                        df_temp.loc[temp.Index,'Width'] = pred.Width\n",
    "                        df_temp.loc[temp.Index,'Y'] = pred.Y\n",
    "                        df_temp.loc[temp.Index,'Height'] = pred.Height\n",
    "                        df_temp.loc[temp.Index,'Z'] = pred.Z\n",
    "                        df_temp.loc[temp.Index,'Depth'] = pred.Depth\n",
    "                        df_temp.loc[temp.Index,'Score'] = pred.Score\n",
    "                        df_temp.loc[temp.Index,'index'] = pred.index\n",
    "\n",
    "                        added = True\n",
    "                        break\n",
    "            if not added:\n",
    "                df_temp =\\\n",
    "                  df_temp\\\n",
    "                  .append(pd.DataFrame([[pred.PatientID,pred.Index[0],pred.Index[1],\n",
    "                                         pred.X,pred.Width,pred.Y,pred.Height,pred.Z,pred.Depth,\n",
    "                                         pred.Score,\n",
    "                                         pred.index]],\n",
    "                                       columns=['PatientID','StudyUID','View',\n",
    "                                                'X','Width','Y','Height','Z','Depth',\n",
    "                                                'Score',\n",
    "                                                'index']),\n",
    "                          ignore_index=True)\n",
    "        df_pred_new = df_pred_new.append(df_temp, ignore_index=True)\n",
    "\n",
    "    df_pred_new = df_pred_new.sort_values(['index']).reset_index(drop=True).drop(columns=['index'])\n",
    "    \n",
    "    return df_pred_new\n",
    "\n",
    "def is_match(lower_prob_pred, higher_prob_pred, slice_offset, min_dist=100):\n",
    "    lower_prob_pred_x = lower_prob_pred.X + lower_prob_pred.Width / 2\n",
    "    lower_prob_pred_y = lower_prob_pred.Y + lower_prob_pred.Height / 2\n",
    "    lower_prob_pred_z = lower_prob_pred.Z + lower_prob_pred.Depth / 2\n",
    "\n",
    "    higher_prob_pred_x = higher_prob_pred.X + higher_prob_pred.Width / 2\n",
    "    higher_prob_pred_y = higher_prob_pred.Y + higher_prob_pred.Height / 2\n",
    "    higher_prob_pred_z = higher_prob_pred.Z + higher_prob_pred.Depth / 2\n",
    "    \n",
    "    # 2D distance between lower and higher probability prediction center points\n",
    "    dist = np.linalg.norm((lower_prob_pred_x - higher_prob_pred_x,\n",
    "                           lower_prob_pred_y - higher_prob_pred_y))\n",
    "\n",
    "    # compute radius based on higher probability prediction box size\n",
    "    dist_threshold =\\\n",
    "        np.sqrt(higher_prob_pred.Width ** 2 + higher_prob_pred.Height ** 2) / 2.0\n",
    "    dist_threshold = max(dist_threshold, min_dist)\n",
    "    slice_diff = np.abs(lower_prob_pred_z - higher_prob_pred_z)\n",
    "\n",
    "    # TP if predicted center within radius and slice within slice offset\n",
    "    return dist <= dist_threshold and slice_diff <= slice_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------\n",
    "# Training Set   \n",
    "# ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Slice (2D) Predictions and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'training'\n",
    "\n",
    "sls = {}\n",
    "vol_ids_temp = []\n",
    "for location in [ \\\n",
    "#                 '<location 1 of predictions for DBT volume slices>'\n",
    "#                 '<location 2 of predictions for DBT volume slices>'\n",
    "#                 .\n",
    "#                 .\n",
    "#                 .\n",
    "                ]:\n",
    "    vol_ids = np.unique([_.split('.')[0] for _ in os.listdir(location)])\n",
    "    print('total number of slices:', len(os.listdir(location)))\n",
    "    print('total number of DBT scans', len(vol_ids))\n",
    "    print('')\n",
    "    for i, vol_id in enumerate(vol_ids):\n",
    "        i += len(vol_ids_temp)\n",
    "        if i not in sls:\n",
    "            sls[i] = {}\n",
    "        l = glob.glob(os.path.join(location,vol_id+'.*'))\n",
    "        for j in range(len(l)):\n",
    "            with open(l[j], 'rb') as f:\n",
    "                sl = pickle.load(f)\n",
    "            sl_idx = int(l[j].rsplit('.',1)[0].rsplit('_')[-1])\n",
    "            if sl_idx in sls[i]:\n",
    "                for key in sls[i][sl_idx].keys():\n",
    "                    sls[i][sl_idx][key] =\\\n",
    "                        np.concatenate((sls[i][sl_idx][key],sl[key]),axis=0)\n",
    "            else:\n",
    "                sls[i][sl_idx] = sl\n",
    "    vol_ids_temp = np.concatenate((vol_ids_temp, vol_ids), axis=0)\n",
    "\n",
    "location = '' # <specified location of SPIE data and metadata>\n",
    "\n",
    "train_paths = pd.read_csv(os.path.join(location,'BCS-DBT file-paths-train.csv'))\n",
    "train_boxes = pd.read_csv(os.path.join(location,'BCS-DBT boxes-train.csv'))\n",
    "train_labels = pd.read_csv(os.path.join(location,'BCS-DBT labels-train.csv'))\n",
    "print('total number of ground truth boxes:', len(train_boxes))\n",
    "print('total number of training set DBT scans:', len(train_labels))\n",
    "prepare_submission = train_paths[['PatientID','StudyUID','View']].copy()\n",
    "prepare_submission['VolID'] =\\\n",
    "    train_paths['descriptive_path'].apply(lambda x: x.rsplit('/',2)[1].split('.')[0])\n",
    "\n",
    "vol_ids = vol_ids_temp\n",
    "\n",
    "i_ = len(vol_ids)\n",
    "\n",
    "subset_labels = pd.DataFrame()\n",
    "for i, vol_id in enumerate(vol_ids):\n",
    "    subset_labels = subset_labels.append(train_labels[prepare_submission['VolID'] == vol_id],\n",
    "                                         ignore_index=True)\n",
    "    if i == i_:\n",
    "        break\n",
    "\n",
    "subset_boxes = pd.DataFrame()\n",
    "for ID in subset_labels[['StudyUID', 'View']].itertuples():\n",
    "    subset_boxes =\\\n",
    "        subset_boxes.append(train_boxes[(train_boxes['StudyUID'] == ID.StudyUID) &\\\n",
    "                                        (train_boxes['View'] == ID.View)],\n",
    "                            ignore_index=True)\n",
    "\n",
    "print('number of ground truth boxes (in split(s)):', len(subset_boxes))\n",
    "print('number of training set dbt scans (in split(s)):', len(subset_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Candidate Generation Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'continuity': np.nan,\n",
    "              'score_threshold': np.nan,\n",
    "              'depth_threshold': np.nan,\n",
    "              'intersection_thresholds': [np.nan, np.nan],\n",
    "              'metrics': [-np.inf, -np.inf]}\n",
    "\n",
    "apply_nms_3D = False\n",
    "\n",
    "intersection_mode = 'IoSIB'\n",
    "box_scores_function = np.mean\n",
    "top_n_scores = 10\n",
    "weighted_boxes_fusion = False\n",
    "\n",
    "for continuity in [0.5]:\n",
    "    for score_threshold in [0.85]:\n",
    "        for depth_threshold in [1]:\n",
    "            for intersection_thresholds in [[0.75, 1]]:\n",
    "                slice_groups = {}\n",
    "                boxes3D = {}\n",
    "                scores = {}\n",
    "                box2D_scores = {}\n",
    "                num_slices = {}\n",
    "                for _ in range(len(sls)):\n",
    "                    slice_groups[_], boxes3D[_], scores[_], box2D_scores[_] =\\\n",
    "                        sls_to_vol(sls[_],\n",
    "                                   continuity=continuity,\n",
    "                                   score_threshold=score_threshold,\n",
    "                                   depth_threshold=depth_threshold,\n",
    "                                   intersection_thresholds=intersection_thresholds,\n",
    "                                   intersection_mode=intersection_mode,\n",
    "                                   box_scores_function=box_scores_function,\n",
    "                                   top_n_scores=top_n_scores,\n",
    "                                   weighted_boxes_fusion=weighted_boxes_fusion)\n",
    "                    num_slices[_] = len(sls[_])\n",
    "                    if _ == i_:\n",
    "                        break\n",
    "                print('*****************************')\n",
    "                print('* Snapshot of sample volume *')\n",
    "                print('*****************************')\n",
    "                print('volume index:', _)\n",
    "                print('number of slices:', len(sls[_]))\n",
    "                print('size of slice groups:')\n",
    "                for __ in slice_groups[_]:\n",
    "                    print(len(slice_groups[_][__]))\n",
    "                print('boxes:', boxes3D[_])\n",
    "                print('boxes:', scores[_])\n",
    "                \n",
    "                submission_file = pd.DataFrame(columns=['PatientID',\n",
    "                                                        'StudyUID',\n",
    "                                                        'View',\n",
    "                                                        'X',\n",
    "                                                        'Width',\n",
    "                                                        'Y',\n",
    "                                                        'Height',\n",
    "                                                        'Z',\n",
    "                                                        'Depth',\n",
    "                                                        'Score'])\n",
    "                PatientID_dict = {}\n",
    "                for i, vol_id in enumerate(vol_ids):\n",
    "                    prepare_submission_row =\\\n",
    "                        prepare_submission[prepare_submission['VolID'] == vol_id]\n",
    "\n",
    "                    PatientID = list(prepare_submission_row['PatientID'])[0]\n",
    "                    StudyUID = list(prepare_submission_row['StudyUID'])[0]\n",
    "                    View = list(prepare_submission_row['View'])[0]\n",
    "\n",
    "                    if PatientID in PatientID_dict:\n",
    "                        if not StudyUID in PatientID_dict[PatientID]:\n",
    "                            PatientID_dict[PatientID][StudyUID] = {}\n",
    "                    else:\n",
    "                        PatientID_dict[PatientID] = {}\n",
    "                        PatientID_dict[PatientID][StudyUID] = {}\n",
    "                    PatientID_dict[PatientID][StudyUID][View] = num_slices[i]\n",
    "                    for j in boxes3D[i]:\n",
    "                        X = int(boxes3D[i][j]['x'][0])\n",
    "                        Width = int(np.diff(boxes3D[i][j]['x']))\n",
    "                        Y = int(boxes3D[i][j]['y'][0])\n",
    "                        Height = int(np.diff(boxes3D[i][j]['y']))\n",
    "                        Z = int(boxes3D[i][j]['z'][0])\n",
    "                        Depth = int(np.diff(boxes3D[i][j]['z'])) + 1\n",
    "                        Score = scores[i][j]\n",
    "                        submission_file_row = pd.DataFrame([[PatientID,\n",
    "                                                             StudyUID,\n",
    "                                                             View,\n",
    "                                                             X,\n",
    "                                                             Width,\n",
    "                                                             Y,\n",
    "                                                             Height,\n",
    "                                                             Z,\n",
    "                                                             Depth,\n",
    "                                                             Score]],\n",
    "                                                           columns=['PatientID',\n",
    "                                                                    'StudyUID',\n",
    "                                                                    'View',\n",
    "                                                                    'X',\n",
    "                                                                    'Width',\n",
    "                                                                    'Y',\n",
    "                                                                    'Height',\n",
    "                                                                    'Z',\n",
    "                                                                    'Depth',\n",
    "                                                                    'Score'])\n",
    "\n",
    "                        submission_file =\\\n",
    "                            submission_file.append(submission_file_row, ignore_index=True)\n",
    "                    if i == i_:\n",
    "                        break\n",
    "\n",
    "                if apply_nms_3D:\n",
    "                    print('************************************************')\n",
    "                    print('* Non-Maximum Suppression of 3D Candidate List *')\n",
    "                    print('************************************************')\n",
    "                    submission_file = nms_dbtex(submission_file, PatientID_dict)\n",
    "                \n",
    "                print('************************************************')\n",
    "                print('* Snapshot of submission file and ground truth *')\n",
    "                print('************************************************')\n",
    "                print(submission_file.loc[submission_file['PatientID'] == 'DBT-P00060'])\n",
    "                print(train_boxes[train_boxes['PatientID'] == 'DBT-P00060'])\n",
    "                for PatientID in PatientID_dict:\n",
    "                    for StudyUID in PatientID_dict[PatientID]:\n",
    "                        for View in PatientID_dict[PatientID][StudyUID]:\n",
    "                            if not (PatientID == 'DBT-P00060' and\\\n",
    "                                    StudyUID == 'DBT-S00787' and\\\n",
    "                                    View == 'rcc'):\n",
    "                                continue\n",
    "                            for i, df_row_i in submission_file[(submission_file['PatientID'] == PatientID) &\\\n",
    "                                                               (submission_file['StudyUID'] == StudyUID) &\\\n",
    "                                                               (submission_file['View'] == View)].iterrows():\n",
    "                                for j, df_row_j in train_boxes[(train_boxes['PatientID'] == PatientID) &\\\n",
    "                                                               (train_boxes['StudyUID'] == StudyUID) &\\\n",
    "                                                               (train_boxes['View'] == View)].iterrows():\n",
    "                                    print(i, j,\n",
    "                                          PatientID,\n",
    "                                          View,\n",
    "                                          is_tp(df_row_i, df_row_j,\n",
    "                                                slice_offset=PatientID_dict[PatientID][StudyUID][View] / 4))\n",
    "                print('**********************')\n",
    "                print('* Evaluation Metrics *')\n",
    "                print('**********************')\n",
    "                tpr_positive, tpr_all =\\\n",
    "                    evaluate(df_labels=subset_labels,\n",
    "                             df_pred=submission_file,\n",
    "                             df_true=subset_boxes,\n",
    "                             num_slices_info=PatientID_dict,\n",
    "                             fps_per_vol=(1.0, 2.0, 3.0, 4.0))\n",
    "                print('tpr_positive:', tpr_positive)\n",
    "                print('tpr_all:', tpr_all)\n",
    "                print('avg_tpr_positive:', np.mean(tpr_positive[:4]))\n",
    "                print('avg_tpr_all:', np.mean(tpr_all[:4]))\n",
    "                tpr_positive_2, tpr_all_2 =\\\n",
    "                    evaluate(df_labels=subset_labels,\n",
    "                             df_pred=submission_file,\n",
    "                             df_true=subset_boxes,\n",
    "                             num_slices_info=PatientID_dict,\n",
    "                             fps_per_vol=(2.0,))\n",
    "                print('tpr_positive:', tpr_positive_2)\n",
    "                print('tpr_all:', tpr_all_2)\n",
    "\n",
    "                if np.mean(tpr_positive) > parameters['metrics'][0] or \\\n",
    "                   (np.mean(tpr_positive) == parameters['metrics'][0] and \\\n",
    "                    tpr_all_2 > parameters['metrics'][1]):\n",
    "                    parameters.update({'continuity': continuity,\n",
    "                                       'score_threshold': score_threshold,\n",
    "                                       'depth_threshold': depth_threshold,\n",
    "                                       'intersection_thresholds': intersection_thresholds,\n",
    "                                       'metrics': [np.mean(tpr_positive),\n",
    "                                                   tpr_all_2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_predictions = find_tps(df_pred=submission_file,\n",
    "                                    df_true=subset_boxes,\n",
    "                                    num_slices_info=PatientID_dict)\n",
    "training_set_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------\n",
    "# Validation (Test) Set   \n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Slice (2D) Predictions and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'test' # 'validation' 'test'\n",
    "\n",
    "sls = {}\n",
    "for location in [ \\\n",
    "#                 '<location 1 of predictions for DBT volume slices>'\n",
    "#                 '<location 2 of predictions for DBT volume slices>'\n",
    "#                 .\n",
    "#                 .\n",
    "#                 .\n",
    "                ]:\n",
    "    vol_ids = np.unique([_.split('.')[0] for _ in os.listdir(location)])\n",
    "    print('total number of slices:', len(os.listdir(location)))\n",
    "    print('total number of DBT scans', len(vol_ids))\n",
    "    print('')\n",
    "    for i, vol_id in enumerate(vol_ids):\n",
    "        if i not in sls:\n",
    "            sls[i] = {}\n",
    "        l = glob.glob(os.path.join(location,vol_id+'.*'))\n",
    "        for j in range(len(l)):\n",
    "            with open(l[j], 'rb') as f:\n",
    "                sl = pickle.load(f)\n",
    "            sl_idx = int(l[j].rsplit('.',1)[0].rsplit('_')[-1])\n",
    "            if sl_idx in sls[i]:\n",
    "                for key in sls[i][sl_idx].keys():\n",
    "                    sls[i][sl_idx][key] =\\\n",
    "                        np.concatenate((sls[i][sl_idx][key],sl[key]),axis=0)\n",
    "            else:\n",
    "                sls[i][sl_idx] = sl\n",
    "\n",
    "location = '../{}/metadata'.format(data)\n",
    "paths = pd.read_csv(os.path.join(location, 'BCS-DBT file-paths-{}.csv'.format(data)))\n",
    "print('total number of {} set DBT scans:'.format(data), len(paths))\n",
    "prepare_submission = paths[['PatientID','StudyUID','View']].copy()\n",
    "prepare_submission['VolID'] =\\\n",
    "    paths['descriptive_path'].apply(lambda x: x.rsplit('/',2)[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ = len(vol_ids)\n",
    "\n",
    "apply_nms_3D = False\n",
    "\n",
    "continuity = 0.5\n",
    "score_threshold = 0.85\n",
    "depth_threshold = 1\n",
    "intersection_thresholds = [0.75, 1]\n",
    "intersection_mode = 'IoSIB'\n",
    "box_scores_function = np.mean\n",
    "top_n_scores = 10\n",
    "weighted_boxes_fusion = False\n",
    "\n",
    "slice_groups = {}\n",
    "boxes3D = {}\n",
    "scores = {}\n",
    "box2D_scores = {}\n",
    "num_slices = {}\n",
    "for _ in range(len(sls)):\n",
    "    slice_groups[_], boxes3D[_], scores[_], box2D_scores[_] =\\\n",
    "        sls_to_vol(sls[_],\n",
    "                   continuity=continuity,\n",
    "                   score_threshold=score_threshold,\n",
    "                   depth_threshold=depth_threshold,\n",
    "                   intersection_thresholds=intersection_thresholds,\n",
    "                   intersection_mode=intersection_mode,\n",
    "                   box_scores_function=box_scores_function,\n",
    "                   top_n_scores=top_n_scores,\n",
    "                   weighted_boxes_fusion=weighted_boxes_fusion)\n",
    "    num_slices[_] = len(sls[_])\n",
    "    if _ == i_:\n",
    "        break\n",
    "\n",
    "print('*****************************')\n",
    "print('* Snapshot of sample volume *')\n",
    "print('*****************************')\n",
    "print('volume index:', _)\n",
    "print('number of slices:', len(sls[_]))\n",
    "print('size of slice groups:')\n",
    "for __ in slice_groups[_]:\n",
    "    print(len(slice_groups[_][__]))\n",
    "print('boxes:', boxes3D[_])\n",
    "print('scores:', scores[_])\n",
    "\n",
    "submission_file = pd.DataFrame(columns=['PatientID',\n",
    "                                        'StudyUID',\n",
    "                                        'View',\n",
    "                                        'X',\n",
    "                                        'Width',\n",
    "                                        'Y',\n",
    "                                        'Height',\n",
    "                                        'Z',\n",
    "                                        'Depth',\n",
    "                                        'Score'])\n",
    "PatientID_dict = {}\n",
    "for i, vol_id in enumerate(vol_ids):\n",
    "    prepare_submission_row = prepare_submission[prepare_submission['VolID'] == vol_id]\n",
    "    \n",
    "    PatientID = list(prepare_submission_row['PatientID'])[0]\n",
    "    StudyUID = list(prepare_submission_row['StudyUID'])[0]\n",
    "    View = list(prepare_submission_row['View'])[0]\n",
    "    \n",
    "    if PatientID in PatientID_dict:\n",
    "        if not StudyUID in PatientID_dict[PatientID]:\n",
    "            PatientID_dict[PatientID][StudyUID] = {}\n",
    "    else:\n",
    "        PatientID_dict[PatientID] = {}\n",
    "        PatientID_dict[PatientID][StudyUID] = {}\n",
    "    PatientID_dict[PatientID][StudyUID][View] = num_slices[i]\n",
    "    for j in boxes3D[i]:\n",
    "        X = int(boxes3D[i][j]['x'][0])\n",
    "        Width = int(np.diff(boxes3D[i][j]['x']))\n",
    "        Y = int(boxes3D[i][j]['y'][0])\n",
    "        Height = int(np.diff(boxes3D[i][j]['y']))\n",
    "        Z = int(boxes3D[i][j]['z'][0])\n",
    "        Depth = int(np.diff(boxes3D[i][j]['z'])) + 1\n",
    "        Score = scores[i][j]\n",
    "        submission_file_row = pd.DataFrame([[PatientID,\n",
    "                                             StudyUID,\n",
    "                                             View,\n",
    "                                             X,\n",
    "                                             Width,\n",
    "                                             Y,\n",
    "                                             Height,\n",
    "                                             Z,\n",
    "                                             Depth,\n",
    "                                             Score]],\n",
    "                                           columns=['PatientID',\n",
    "                                                    'StudyUID',\n",
    "                                                    'View',\n",
    "                                                    'X',\n",
    "                                                    'Width',\n",
    "                                                    'Y',\n",
    "                                                    'Height',\n",
    "                                                    'Z',\n",
    "                                                    'Depth',\n",
    "                                                    'Score'])\n",
    "\n",
    "        submission_file =\\\n",
    "            submission_file.append(submission_file_row, ignore_index=True)\n",
    "    if i == i_:\n",
    "        break\n",
    "        \n",
    "if apply_nms_3D:\n",
    "    print('************************************************')\n",
    "    print('* Non-Maximum Suppression of 3D Candidate List *')\n",
    "    print('************************************************')\n",
    "    submission_file = nms_dbtex(submission_file, PatientID_dict)\n",
    "\n",
    "print('*******************************')\n",
    "print('* Snapshot of submission file *')\n",
    "print('*******************************')\n",
    "if data == 'validation':\n",
    "    PID = 'DBT-P01293'\n",
    "elif data == 'test':\n",
    "    PID = 'DBT-P02609'\n",
    "print(submission_file.loc[submission_file['PatientID'] == PID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
